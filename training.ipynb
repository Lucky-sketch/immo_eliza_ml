{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows removed from primary_energy_consumption_sqm: 1053\n",
      "upper outliers: 1053\n",
      "\n",
      "Rows removed from nbr_bedrooms: 2866\n",
      "upper outliers: 2866\n",
      "\n",
      "Rows removed from total_area_sqm: 3161\n",
      "upper outliers: 3161\n",
      "\n",
      "Rows removed from nbr_frontages: 20\n",
      "upper outliers: 20\n",
      "Features: \n",
      " ['construction_year', 'total_area_sqm', 'surface_land_sqm', 'nbr_frontages', 'fl_furnished', 'nbr_bedrooms', 'fl_open_fire', 'fl_terrace', 'terrace_sqm', 'primary_energy_consumption_sqm', 'fl_floodzone', 'fl_double_glazing', 'cadastral_income', 'property_type_APARTMENT', 'property_type_HOUSE', 'subproperty_type_APARTMENT', 'subproperty_type_APARTMENT_BLOCK', 'subproperty_type_BUNGALOW', 'subproperty_type_CASTLE', 'subproperty_type_CHALET', 'subproperty_type_COUNTRY_COTTAGE', 'subproperty_type_DUPLEX', 'subproperty_type_EXCEPTIONAL_PROPERTY', 'subproperty_type_FARMHOUSE', 'subproperty_type_FLAT_STUDIO', 'subproperty_type_GROUND_FLOOR', 'subproperty_type_HOUSE', 'subproperty_type_KOT', 'subproperty_type_LOFT', 'subproperty_type_MANOR_HOUSE', 'subproperty_type_MANSION', 'subproperty_type_MIXED_USE_BUILDING', 'subproperty_type_OTHER_PROPERTY', 'subproperty_type_PENTHOUSE', 'subproperty_type_SERVICE_FLAT', 'subproperty_type_TOWN_HOUSE', 'subproperty_type_TRIPLEX', 'subproperty_type_VILLA', 'locality_Aalst', 'locality_Antwerp', 'locality_Arlon', 'locality_Ath', 'locality_Bastogne', 'locality_Brugge', 'locality_Brussels', 'locality_Charleroi', 'locality_Dendermonde', 'locality_Diksmuide', 'locality_Dinant', 'locality_Eeklo', 'locality_Gent', 'locality_Halle-Vilvoorde', 'locality_Hasselt', 'locality_Huy', 'locality_Ieper', 'locality_Kortrijk', 'locality_Leuven', 'locality_Liège', 'locality_MISSING', 'locality_Maaseik', 'locality_Marche-en-Famenne', 'locality_Mechelen', 'locality_Mons', 'locality_Mouscron', 'locality_Namur', 'locality_Neufchâteau', 'locality_Nivelles', 'locality_Oostend', 'locality_Oudenaarde', 'locality_Philippeville', 'locality_Roeselare', 'locality_Sint-Niklaas', 'locality_Soignies', 'locality_Thuin', 'locality_Tielt', 'locality_Tongeren', 'locality_Tournai', 'locality_Turnhout', 'locality_Verviers', 'locality_Veurne', 'locality_Virton', 'locality_Waremme', 'equipped_kitchen_HYPER_EQUIPPED', 'equipped_kitchen_INSTALLED', 'equipped_kitchen_MISSING', 'equipped_kitchen_NOT_INSTALLED', 'equipped_kitchen_SEMI_EQUIPPED', 'equipped_kitchen_USA_HYPER_EQUIPPED', 'equipped_kitchen_USA_INSTALLED', 'equipped_kitchen_USA_SEMI_EQUIPPED', 'equipped_kitchen_USA_UNINSTALLED', 'state_building_AS_NEW', 'state_building_GOOD', 'state_building_JUST_RENOVATED', 'state_building_MISSING', 'state_building_TO_BE_DONE_UP', 'state_building_TO_RENOVATE', 'state_building_TO_RESTORE', 'heating_type_CARBON', 'heating_type_ELECTRIC', 'heating_type_FUELOIL', 'heating_type_GAS', 'heating_type_MISSING', 'heating_type_PELLET', 'heating_type_SOLAR', 'heating_type_WOOD', 'epc_A', 'epc_A+', 'epc_A++', 'epc_B', 'epc_C', 'epc_D', 'epc_E', 'epc_F', 'epc_G', 'epc_MISSING']\n",
      "Boost: Train R² score: 0.746673651380662\n",
      "Boost: Test R² score: 0.6750857815856393\n",
      "Line: Train R² score: 0.3408951176356557\n",
      "Line: Test R² score: 0.37206659404415365\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Trains a linear regression model on the full dataset and stores output.\"\"\"\n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/properties.csv\")\n",
    "# IQR Outlier deletion\n",
    "\n",
    "for column in [\n",
    "    # \"Price\",\n",
    "    \"primary_energy_consumption_sqm\",\n",
    "    \"nbr_bedrooms\",\n",
    "    \"total_area_sqm\",\n",
    "    \"nbr_frontages\",\n",
    "]:\n",
    "    previous_count = data.shape[0]\n",
    "\n",
    "    # IQR\n",
    "    # Calculate the upper and lower limits\n",
    "    Q1 = data[column].quantile(0.1)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Create arrays of Boolean values indicating the outlier rows\n",
    "    upper_array = np.where(data[column] >= upper)[0]\n",
    "\n",
    "    # Removing the outliers\n",
    "    numerical_data_IQR = data.drop(index=data.index[upper_array])\n",
    "\n",
    "    print(\n",
    "        f\"\\nRows removed from {column}:\",\n",
    "        previous_count - numerical_data_IQR.shape[0],\n",
    "    )\n",
    "    print(\"upper outliers:\", len(upper_array))\n",
    "\n",
    "    categorical_features = [\n",
    "        \"property_type\",\n",
    "        \"subproperty_type\",\n",
    "        \"locality\",\n",
    "        \"equipped_kitchen\",\n",
    "        \"state_building\",\n",
    "        \"heating_type\",\n",
    "        \"epc\",\n",
    "    ]\n",
    "    numerical_features = [\n",
    "        \"construction_year\",\n",
    "        \"total_area_sqm\",\n",
    "        \"surface_land_sqm\",\n",
    "        \"nbr_frontages\",\n",
    "        \"fl_furnished\",\n",
    "        \"nbr_bedrooms\",\n",
    "        \"fl_open_fire\",\n",
    "        \"fl_terrace\",\n",
    "        \"terrace_sqm\",\n",
    "        \"primary_energy_consumption_sqm\",\n",
    "        \"fl_floodzone\",\n",
    "        \"fl_double_glazing\",\n",
    "        \"cadastral_income\",\n",
    "    ]\n",
    "    # Define features to use\n",
    "    X = data\n",
    "    y = data[\"price\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=505\n",
    "    )\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(\n",
    "    strategy=\"mean\"\n",
    ")  \n",
    "\n",
    "# Fit the imputer to the data\n",
    "imputer.fit(X_train[numerical_features])\n",
    "\n",
    "# Transform the data by replacing NaN values with the imputed values\n",
    "X_train[numerical_features] = imputer.transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = imputer.transform(X_test[numerical_features])\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(\n",
    "    X_train[categorical_features]\n",
    ")  # Note the double brackets to create a DataFrame with a single column\n",
    "X_train_features = enc.transform(X_train[categorical_features]).toarray()\n",
    "X_train_features_df = pd.DataFrame(\n",
    "    X_train_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "X_test_features = enc.transform(X_test[categorical_features]).toarray()\n",
    "X_test_features_df = pd.DataFrame(\n",
    "    X_test_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[numerical_features])\n",
    "scaled_train = scaler.transform(X_train[numerical_features])\n",
    "scaled_test = scaler.transform(X_test[numerical_features])\n",
    "scaled_train_df = pd.DataFrame(scaled_train, columns=scaler.get_feature_names_out())\n",
    "scaled_test_df = pd.DataFrame(scaled_test, columns=scaler.get_feature_names_out())\n",
    "\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        scaled_train_df.reset_index(drop=True),\n",
    "        X_train_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        scaled_test_df.reset_index(drop=True),\n",
    "        X_test_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(f\"Features: \\n {X_train.columns.tolist()}\")\n",
    "# Define the model\n",
    "model3 = xgb.XGBRegressor(reg_lambda=5, reg_alpha=1, objective='reg:squarederror', \n",
    "                        n_estimators=500, min_child_weight=14, max_depth=6, subsample =0.8, \n",
    "                        learning_rate=0.03, gamma=0.1, colsample_bytree=0.8, booster='gbtree')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model3.fit(X_train, y_train)\n",
    "# Predict\n",
    "train_score = r2_score(y_train, model3.predict(X_train))\n",
    "test_score = r2_score(y_test, model3.predict(X_test))\n",
    "print(f\"Boost: Train R² score: {train_score}\")\n",
    "print(f\"Boost: Test R² score: {test_score}\")\n",
    "# Train the model for LinearRegression\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "train_score_line = r2_score(y_train, model2.predict(X_train))\n",
    "test_score_line = r2_score(y_test, model2.predict(X_test))\n",
    "print(f\"Line: Train R² score: {train_score_line}\")\n",
    "print(f\"Line: Test R² score: {test_score_line}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae for train: 60614.538103274426\n",
      "mae for test: 94643.19913834578\n",
      "Line: Train R² score: 0.8649242981043737\n",
      "Line: Test R² score: 0.6747667937269607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/properties.csv\")\n",
    "# IQR Outlier deletion\n",
    "\n",
    "\n",
    "categorical_features = [\n",
    "    \"property_type\",\n",
    "    \"subproperty_type\",\n",
    "    \"locality\",\n",
    "    \"equipped_kitchen\",\n",
    "    \"state_building\",\n",
    "    \"heating_type\",\n",
    "    \"epc\",\n",
    "]\n",
    "numerical_features = [\n",
    "    \"construction_year\",\n",
    "    \"total_area_sqm\",\n",
    "    \"surface_land_sqm\",\n",
    "    \"nbr_frontages\",\n",
    "    \"fl_furnished\",\n",
    "    \"nbr_bedrooms\",\n",
    "    \"fl_open_fire\",\n",
    "    \"fl_terrace\",\n",
    "    \"terrace_sqm\",\n",
    "    \"primary_energy_consumption_sqm\",\n",
    "    \"fl_floodzone\",\n",
    "        \"fl_double_glazing\",\n",
    "        \"cadastral_income\",\n",
    "    ]\n",
    "    # Define features to use\n",
    "X = data\n",
    "y = data[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=505)\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(\n",
    "    X_train[categorical_features]\n",
    ")  # Note the double brackets to create a DataFrame with a single column\n",
    "X_train_features = enc.transform(X_train[categorical_features]).toarray()\n",
    "X_train_features_df = pd.DataFrame(\n",
    "    X_train_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "X_test_features = enc.transform(X_test[categorical_features]).toarray()\n",
    "X_test_features_df = pd.DataFrame(\n",
    "    X_test_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        X_train[numerical_features].reset_index(drop=True),\n",
    "        X_train_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        X_test[numerical_features].reset_index(drop=True),\n",
    "        X_test_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "model4 = RandomForestRegressor(\n",
    "    n_estimators=1400,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=30,\n",
    "    bootstrap=True\n",
    ")\n",
    "model4.fit(X_train, y_train)\n",
    "preds = model4.predict(X_train)\n",
    "preds_test= model4.predict(X_test)\n",
    "mae_train = mean_absolute_error(y_train, preds)\n",
    "mae_test = mean_absolute_error(y_test, preds_test)\n",
    "print(f\"mae for train: {mae_train}\")\n",
    "print(f\"mae for test: {mae_test}\")\n",
    "train_score_line = r2_score(y_train, preds)\n",
    "test_score_line = r2_score(y_test, preds_test)\n",
    "print(f\"Line: Train R² score: {train_score_line}\")\n",
    "print(f\"Line: Test R² score: {test_score_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id     price property_type    subproperty_type            region  \\\n",
      "0      34221000  225000.0     APARTMENT           APARTMENT          Flanders   \n",
      "1       2104000  449000.0         HOUSE               HOUSE          Flanders   \n",
      "2      34036000  335000.0     APARTMENT           APARTMENT  Brussels-Capital   \n",
      "3      58496000  501000.0         HOUSE               HOUSE          Flanders   \n",
      "4      48727000  982700.0     APARTMENT              DUPLEX          Wallonia   \n",
      "...         ...       ...           ...                 ...               ...   \n",
      "75506  30785000  210000.0     APARTMENT           APARTMENT          Wallonia   \n",
      "75507  13524000  780000.0     APARTMENT           PENTHOUSE  Brussels-Capital   \n",
      "75508  43812000  798000.0         HOUSE  MIXED_USE_BUILDING  Brussels-Capital   \n",
      "75509  49707000  575000.0         HOUSE               VILLA          Flanders   \n",
      "75510  65278000  515000.0     APARTMENT           PENTHOUSE          Flanders   \n",
      "\n",
      "              province  locality  zip_code   latitude  longitude  ...  \\\n",
      "0              Antwerp   Antwerp      2050  51.217172   4.379982  ...   \n",
      "1        East Flanders      Gent      9185  51.174944   3.845248  ...   \n",
      "2             Brussels  Brussels      1070  50.842043   4.334543  ...   \n",
      "3              Antwerp  Turnhout      2275  51.238312   4.817192  ...   \n",
      "4      Walloon Brabant  Nivelles      1410        NaN        NaN  ...   \n",
      "...                ...       ...       ...        ...        ...  ...   \n",
      "75506          Hainaut   Tournai      7640        NaN        NaN  ...   \n",
      "75507         Brussels  Brussels      1200  50.840183   4.435570  ...   \n",
      "75508         Brussels  Brussels      1080        NaN        NaN  ...   \n",
      "75509    West Flanders    Veurne      8670        NaN        NaN  ...   \n",
      "75510          Antwerp   Antwerp      2000  51.220753   4.410247  ...   \n",
      "\n",
      "       fl_garden  garden_sqm  fl_swimming_pool  fl_floodzone  state_building  \\\n",
      "0              0         0.0                 0             0         MISSING   \n",
      "1              0         0.0                 0             0         MISSING   \n",
      "2              0         0.0                 0             1          AS_NEW   \n",
      "3              0         0.0                 0             1         MISSING   \n",
      "4              1       142.0                 0             0          AS_NEW   \n",
      "...          ...         ...               ...           ...             ...   \n",
      "75506          0         0.0                 0             1          AS_NEW   \n",
      "75507          0         0.0                 0             0          AS_NEW   \n",
      "75508          0         0.0                 0             1     TO_RENOVATE   \n",
      "75509          1         NaN                 0             1          AS_NEW   \n",
      "75510          0         0.0                 0             0         MISSING   \n",
      "\n",
      "      primary_energy_consumption_sqm      epc  heating_type  \\\n",
      "0                              231.0        C           GAS   \n",
      "1                              221.0        C       MISSING   \n",
      "2                                NaN  MISSING           GAS   \n",
      "3                               99.0        A       MISSING   \n",
      "4                               19.0       A+           GAS   \n",
      "...                              ...      ...           ...   \n",
      "75506                            NaN  MISSING       MISSING   \n",
      "75507                           95.0        B           GAS   \n",
      "75508                          351.0        G           GAS   \n",
      "75509                          269.0        C           GAS   \n",
      "75510                            NaN  MISSING       MISSING   \n",
      "\n",
      "       fl_double_glazing  cadastral_income  \n",
      "0                      1             922.0  \n",
      "1                      1             406.0  \n",
      "2                      0               NaN  \n",
      "3                      0               NaN  \n",
      "4                      0               NaN  \n",
      "...                  ...               ...  \n",
      "75506                  1               NaN  \n",
      "75507                  1               NaN  \n",
      "75508                  0               NaN  \n",
      "75509                  1             795.0  \n",
      "75510                  1               NaN  \n",
      "\n",
      "[75511 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  38.1s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  38.2s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time= 4.3min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time= 3.5min\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "6 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.57084834 0.5736376         nan 0.60761011        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m rf, param_distributions \u001b[38;5;241m=\u001b[39m random_grid, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1008\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1006\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows removed from primary_energy_consumption_sqm: 1053\n",
      "upper outliers: 1053\n",
      "\n",
      "Rows removed from nbr_bedrooms: 2866\n",
      "upper outliers: 2866\n",
      "\n",
      "Rows removed from total_area_sqm: 3161\n",
      "upper outliers: 3161\n",
      "\n",
      "Rows removed from nbr_frontages: 20\n",
      "upper outliers: 20\n",
      "Features: \n",
      " ['latitude', 'longitude', 'construction_year', 'total_area_sqm', 'surface_land_sqm', 'nbr_frontages', 'fl_furnished', 'nbr_bedrooms', 'fl_open_fire', 'fl_terrace', 'terrace_sqm', 'primary_energy_consumption_sqm', 'fl_floodzone', 'fl_double_glazing', 'cadastral_income', 'property_type_APARTMENT', 'property_type_HOUSE', 'subproperty_type_APARTMENT', 'subproperty_type_APARTMENT_BLOCK', 'subproperty_type_BUNGALOW', 'subproperty_type_CASTLE', 'subproperty_type_CHALET', 'subproperty_type_COUNTRY_COTTAGE', 'subproperty_type_DUPLEX', 'subproperty_type_EXCEPTIONAL_PROPERTY', 'subproperty_type_FARMHOUSE', 'subproperty_type_FLAT_STUDIO', 'subproperty_type_GROUND_FLOOR', 'subproperty_type_HOUSE', 'subproperty_type_KOT', 'subproperty_type_LOFT', 'subproperty_type_MANOR_HOUSE', 'subproperty_type_MANSION', 'subproperty_type_MIXED_USE_BUILDING', 'subproperty_type_OTHER_PROPERTY', 'subproperty_type_PENTHOUSE', 'subproperty_type_SERVICE_FLAT', 'subproperty_type_TOWN_HOUSE', 'subproperty_type_TRIPLEX', 'subproperty_type_VILLA', 'locality_Aalst', 'locality_Antwerp', 'locality_Arlon', 'locality_Ath', 'locality_Bastogne', 'locality_Brugge', 'locality_Brussels', 'locality_Charleroi', 'locality_Dendermonde', 'locality_Diksmuide', 'locality_Dinant', 'locality_Eeklo', 'locality_Gent', 'locality_Halle-Vilvoorde', 'locality_Hasselt', 'locality_Huy', 'locality_Ieper', 'locality_Kortrijk', 'locality_Leuven', 'locality_Liège', 'locality_MISSING', 'locality_Maaseik', 'locality_Marche-en-Famenne', 'locality_Mechelen', 'locality_Mons', 'locality_Mouscron', 'locality_Namur', 'locality_Neufchâteau', 'locality_Nivelles', 'locality_Oostend', 'locality_Oudenaarde', 'locality_Philippeville', 'locality_Roeselare', 'locality_Sint-Niklaas', 'locality_Soignies', 'locality_Thuin', 'locality_Tielt', 'locality_Tongeren', 'locality_Tournai', 'locality_Turnhout', 'locality_Verviers', 'locality_Veurne', 'locality_Virton', 'locality_Waremme', 'equipped_kitchen_HYPER_EQUIPPED', 'equipped_kitchen_INSTALLED', 'equipped_kitchen_MISSING', 'equipped_kitchen_NOT_INSTALLED', 'equipped_kitchen_SEMI_EQUIPPED', 'equipped_kitchen_USA_HYPER_EQUIPPED', 'equipped_kitchen_USA_INSTALLED', 'equipped_kitchen_USA_SEMI_EQUIPPED', 'equipped_kitchen_USA_UNINSTALLED', 'state_building_AS_NEW', 'state_building_GOOD', 'state_building_JUST_RENOVATED', 'state_building_MISSING', 'state_building_TO_BE_DONE_UP', 'state_building_TO_RENOVATE', 'state_building_TO_RESTORE', 'heating_type_CARBON', 'heating_type_ELECTRIC', 'heating_type_FUELOIL', 'heating_type_GAS', 'heating_type_MISSING', 'heating_type_PELLET', 'heating_type_SOLAR', 'heating_type_WOOD', 'epc_A', 'epc_A+', 'epc_A++', 'epc_B', 'epc_C', 'epc_D', 'epc_E', 'epc_F', 'epc_G', 'epc_MISSING']\n",
      "Boost: Train R² score: 0.7495555630741318\n",
      "Boost: Test R² score: 0.7307165208264788\n",
      "Line: Train R² score: 0.34131932376585494\n",
      "Line: Test R² score: 0.3729351693861307\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Trains a linear regression model on the full dataset and stores output.\"\"\"\n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/properties.csv\")\n",
    "# IQR Outlier deletion\n",
    "\n",
    "for column in [\n",
    "    # \"Price\",\n",
    "    \"primary_energy_consumption_sqm\",\n",
    "    \"nbr_bedrooms\",\n",
    "    \"total_area_sqm\",\n",
    "    \"nbr_frontages\",\n",
    "]:\n",
    "    previous_count = data.shape[0]\n",
    "\n",
    "    # IQR\n",
    "    # Calculate the upper and lower limits\n",
    "    Q1 = data[column].quantile(0.1)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Create arrays of Boolean values indicating the outlier rows\n",
    "    upper_array = np.where(data[column] >= upper)[0]\n",
    "\n",
    "    # Removing the outliers\n",
    "    numerical_data_IQR = data.drop(index=data.index[upper_array])\n",
    "\n",
    "    print(\n",
    "        f\"\\nRows removed from {column}:\",\n",
    "        previous_count - numerical_data_IQR.shape[0],\n",
    "    )\n",
    "    print(\"upper outliers:\", len(upper_array))\n",
    "\n",
    "    categorical_features = [\n",
    "        \"property_type\",\n",
    "        \"subproperty_type\",\n",
    "        \"locality\",\n",
    "        \"equipped_kitchen\",\n",
    "        \"state_building\",\n",
    "        \"heating_type\",\n",
    "        \"epc\",\n",
    "    ]\n",
    "    numerical_features = [\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        \"construction_year\",\n",
    "        \"total_area_sqm\",\n",
    "        \"surface_land_sqm\",\n",
    "        \"nbr_frontages\",\n",
    "        \"fl_furnished\",\n",
    "        \"nbr_bedrooms\",\n",
    "        \"fl_open_fire\",\n",
    "        \"fl_terrace\",\n",
    "        \"terrace_sqm\",\n",
    "        \"primary_energy_consumption_sqm\",\n",
    "        \"fl_floodzone\",\n",
    "        \"fl_double_glazing\",\n",
    "        \"cadastral_income\",\n",
    "    ]\n",
    "    # Define features to use\n",
    "    X = data\n",
    "    y = data[\"price\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=505\n",
    "    )\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(\n",
    "    X_train[categorical_features]\n",
    ")  # Note the double brackets to create a DataFrame with a single column\n",
    "X_train_features = enc.transform(X_train[categorical_features]).toarray()\n",
    "X_train_features_df = pd.DataFrame(\n",
    "    X_train_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "X_test_features = enc.transform(X_test[categorical_features]).toarray()\n",
    "X_test_features_df = pd.DataFrame(\n",
    "    X_test_features, columns=enc.get_feature_names_out()\n",
    ")\n",
    "\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        X_train[numerical_features].reset_index(drop=True),\n",
    "        X_train_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        X_test[numerical_features].reset_index(drop=True),\n",
    "        X_test_features_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "    \n",
    "print(f\"Features: \\n {X_train.columns.tolist()}\")\n",
    "\n",
    "# Define the model\n",
    "model3 = xgb.XGBRegressor(\n",
    "    reg_lambda=3,  # Adjust regularization parameters\n",
    "    reg_alpha=0.5,\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=25,  # Increase minimum child weight\n",
    "    max_depth=5,  # Decrease maximum depth\n",
    "    learning_rate=0.01,  # Decrease learning rate\n",
    "    gamma=0.1,\n",
    "    colsample_bytree=0.8,\n",
    "    booster='gbtree'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model3.fit(X_train, y_train)\n",
    "preds = model3.predict(X_train)\n",
    "# Predict\n",
    "train_score = r2_score(y_train, model3.predict(X_train))\n",
    "test_score = r2_score(y_test, model3.predict(X_test))\n",
    "print(f\"Boost: Train R² score: {train_score}\")\n",
    "print(f\"Boost: Test R² score: {test_score}\")\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(\n",
    "    strategy=\"mean\"\n",
    ")  # You can also use 'median', 'most_frequent', or 'constant'\n",
    "\n",
    "# Fit the imputer to the data\n",
    "imputer.fit(X_train[numerical_features])\n",
    "\n",
    "# Transform the data by replacing NaN values with the imputed values\n",
    "X_train[numerical_features] = imputer.transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = imputer.transform(X_test[numerical_features])\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[numerical_features])\n",
    "scaled_train = scaler.transform(X_train[numerical_features])\n",
    "scaled_test = scaler.transform(X_test[numerical_features])\n",
    "scaled_train_df = pd.DataFrame(scaled_train, columns=scaler.get_feature_names_out())\n",
    "scaled_test_df = pd.DataFrame(scaled_test, columns=scaler.get_feature_names_out())\n",
    "\n",
    "X_train = pd.concat(\n",
    "    [\n",
    "        scaled_train_df.reset_index(drop=True),\n",
    "        pd.DataFrame(X_train_features_df),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        scaled_test_df.reset_index(drop=True),\n",
    "        pd.DataFrame(X_test_features_df),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Train the model for LinearRegression\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "train_score_line = r2_score(y_train, model2.predict(X_train))\n",
    "test_score_line = r2_score(y_test, model2.predict(X_test))\n",
    "print(f\"Line: Train R² score: {train_score_line}\")\n",
    "print(f\"Line: Test R² score: {test_score_line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "y_train = y_train[200:500]\n",
    "preds = preds[200:500]\n",
    "# Assuming preds is a pandas Series or DataFrame containing the predicted values\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.scatter(y_train.index, preds, c='red', label='Predicted', s=5)  # Set the size to 10\n",
    "plt.scatter(y_train.index, y_train, c='blue', label='Actual', s=5)   # Set the size to 10\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
